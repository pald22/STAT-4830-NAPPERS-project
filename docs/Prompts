As a part of an assignment I have to hand in tomorrow, I need to write a self critique. Here are the instructions provided: Self-Critique Guidelines Your self-critique should be a separate document that helps you plan concrete improvements for your next draft. Keep it focused and actionable - max 1 page. How to Write Your Self-Critique Follow the OODA (Observe, Orient, Decide, Act) process: OBSERVE: Read your report critically Read it as if you're seeing it for the first time Run your code again, checking results Note initial reactions and questions ORIENT: Analyze your work Write these sections: Strengths (Max 3 bullet points) Example: "Clear problem statement with concrete real-world impact" Areas for Improvement (Max 3 bullet points) Example: "Mathematical formulation needs more rigor - currently just intuitive description" Critical Risks/Assumptions (2-3 sentences) Example: "Assuming dataset will fit in memory. Need to test with realistic data size." DECIDE: Plan your next steps Write this section: Concrete Next Actions (Max 3 bullet points) Must directly address your "Areas for Improvement" Be specific and achievable within a week Example: "Write out optimization objective function with constraints" ACT: Prepare for execution Write this section: Resource Needs (2-3 sentences) What tools/knowledge/help do you need? Be specific about blockers Example: "Need to learn PyTorch autograd for custom gradients. Will use tutorial X." Tips for Effective Self-Critique Be brutally honest - this is for you Focus on what you can change next week Prioritize - don't list everything Think about code AND report Consider your reader's perspective Common Pitfalls to Avoid Vague improvements ("make it better") Too many actions (unfocused) Just listing problems without solutions Ignoring technical depth Forgetting about implementation Using AI Help Feel free to: Ask an LLM to critique your report Compare its feedback with yours Use it to brainstorm improvements But your final critique should reflect your judgment. Remember: The goal is to have a clear plan for your next draft. Quality > Quantity. We had a meeting with our professor yesterday. There is a group from last year who did a very similar project with our same dataset. One of the things we really want to improve is differentiating ourselves from that project. The past project focused on minimizing transaction cost. Here is what the last group included on their gitnub: High-Level Summary Problem Statement: Traditional portfolio strategies often fail under real-world market stress. The challenge is to develop a trading algorithm that is robust to market shocks and adapts to changing conditions, aiming for strong risk-adjusted returns while managing drawdown, turnover, and concentration risk. Approach: We developed PRISM, a dynamic portfolio optimizer using Online Gradient Descent (OGD) implemented in PyTorch. It optimizes a multi-objective function balancing Sortino ratio, maximum drawdown, portfolio turnover, and concentration penalties (measured via Effective Number of Positions). The model processes market data sequentially, updating portfolio weights daily based on rolling window calculations of these metrics. Key Findings/Contributions: Developed a dynamic, multi-objective portfolio optimizer capable of adapting daily to market shifts. The optimizer, balancing Sortino, Max Drawdown, Turnover, and Concentration, consistently outperformed equal-weighted benchmarks in backtests. Identified and quantified the trade-offs between maximizing returns and controlling risk factors like drawdown and concentration, particularly in tech-heavy portfolios. Implemented the solution using PyTorch, leveraging automatic differentiation for gradient-based optimization. Provided a reusable framework (src/) for implementing and testing similar dynamic portfolio optimization strategies. Created an interactive demo showcasing portfolio evolution over time (Demo Link). Another thing our professor suggested was using different datasets from the previous group. Or maybe angling ourselves towards ESG strategies. He mentioned that gradient descent is a potential method but we can also explore others. Another idea we had was integrating an LLM newsfeed to the model so it can trade based on the most current news summaries (5.1 Thinking).  

As a part of an assignment I have to hand in tomorrow, I need to write a self critique. Here are the instructions provided: Self-Critique Guidelines Your self-critique should be a separate document that helps you plan concrete improvements for your next draft. Keep it focused and actionable - max 1 page. How to Write Your Self-Critique Follow the OODA (Observe, Orient, Decide, Act) process: OBSERVE: Read your report critically Read it as if you're seeing it for the first time Run your code again, checking results Note initial reactions and questions ORIENT: Analyze your work Write these sections: Strengths (Max 3 bullet points) Example: "Clear problem statement with concrete real-world impact" Areas for Improvement (Max 3 bullet points) Example: "Mathematical formulation needs more rigor - currently just intuitive description" Critical Risks/Assumptions (2-3 sentences) Example: "Assuming dataset will fit in memory. Need to test with realistic data size." DECIDE: Plan your next steps Write this section: Concrete Next Actions (Max 3 bullet points) Must directly address your "Areas for Improvement" Be specific and achievable within a week Example: "Write out optimization objective function with constraints" ACT: Prepare for execution Write this section: Resource Needs (2-3 sentences) What tools/knowledge/help do you need? Be specific about blockers Example: "Need to learn PyTorch autograd for custom gradients. Will use tutorial X." Tips for Effective Self-Critique Be brutally honest - this is for you Focus on what you can change next week Prioritize - don't list everything Think about code AND report Consider your reader's perspective Common Pitfalls to Avoid Vague improvements ("make it better") Too many actions (unfocused) Just listing problems without solutions Ignoring technical depth Forgetting about implementation Using AI Help Feel free to: Ask an LLM to critique your report Compare its feedback with yours Use it to brainstorm improvements But your final critique should reflect your judgment. Remember: The goal is to have a clear plan for your next draft. Quality > Quantity. We had a meeting with our professor yesterday. There is a group from last year who did a very similar project with our same dataset. One of the things we really want to improve is differentiating ourselves from that project. The past project focused on minimizing transaction cost. Here is what the last group included on their gitnub: High-Level Summary Problem Statement: Traditional portfolio strategies often fail under real-world market stress. The challenge is to develop a trading algorithm that is robust to market shocks and adapts to changing conditions, aiming for strong risk-adjusted returns while managing drawdown, turnover, and concentration risk. Approach: We developed PRISM, a dynamic portfolio optimizer using Online Gradient Descent (OGD) implemented in PyTorch. It optimizes a multi-objective function balancing Sortino ratio, maximum drawdown, portfolio turnover, and concentration penalties (measured via Effective Number of Positions). The model processes market data sequentially, updating portfolio weights daily based on rolling window calculations of these metrics. Key Findings/Contributions: Developed a dynamic, multi-objective portfolio optimizer capable of adapting daily to market shifts. The optimizer, balancing Sortino, Max Drawdown, Turnover, and Concentration, consistently outperformed equal-weighted benchmarks in backtests. Identified and quantified the trade-offs between maximizing returns and controlling risk factors like drawdown and concentration, particularly in tech-heavy portfolios. Implemented the solution using PyTorch, leveraging automatic differentiation for gradient-based optimization. Provided a reusable framework (src/) for implementing and testing similar dynamic portfolio optimization strategies. Created an interactive demo showcasing portfolio evolution over time (Demo Link). Another thing our professor suggested was using different datasets from the previous group. Or maybe angling ourselves towards ESG strategies. He mentioned that gradient descent is a potential method but we can also explore others. Another idea we had was integrating an LLM newsfeed to the model so it can trade based on the most current news summaries. Think deeply about this issue. 

Can you write this in one page and maybe paragraph-style. Also, today at our meeting our group discussed using skewness tensor as our alternative optimization avenue to minimize covariance and maximize skew. We would incorporate this strategy into the loss function. Also, in terms of incorporating a newsfeed from an LLM, we talked about potentially using BloombergGPT. Incorporate these updates.

To make this more specific, scrape our github (https://github.com/pald22/STAT-4830-NAPPERS-project) and the github of the team who did the similar project(https://github.com/dhruv575/PRISM/tree/main). Also, here is our professor's github: (https://github.com/damek/STAT-4830-project-base).

